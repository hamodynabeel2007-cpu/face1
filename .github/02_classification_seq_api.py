# -*- coding: utf-8 -*-
"""02_Classification_Seq_API.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17uMskpTx2i1sfdWrrPdgLP4Mke0Nsgum

# Classification with NN

## Loading the Data
"""

!pip install tensorflow

from tensorflow.keras.datasets import fashion_mnist

(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

x_train.shape

x_test.shape

x_train[0]

import matplotlib.pyplot as plt

plt.imshow(x_train[5], cmap="binary")
plt.show();

y_train[0]

# The labels in Fashion MNIST are 0-9. We need to map them to names:
class_names = ["T-shirt/top", "Trouser", "Pullover", "Dress", "Coat",
               "Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"]

plt.figure(figsize=(10, 10))
for i in range(25):
    plt.subplot(5, 5, i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(x_train[i], cmap="binary")
    # y_train[i] is the number; class_names[y_train[i]] is the word
    plt.xlabel(class_names[y_train[i]])
plt.show()

x_val   = x_train[50000:]
x_train = x_train[:50000]
y_val   = y_train[50000:]
y_train = y_train[:50000]

y_train[:30]

set(y_train)

import pandas as pd

pd.Series(y_train).value_counts()

"""## Preprocessing"""

x_train[0]

x_train[0]/256

x_train = x_train / 256
#x_val   = x_val / 256
x_test  = x_test/256

y_train

"""- No difference between label encoder and ordinal encodel
- Label encoder -> y (one column)
- Ordinal encoder -> X (one or more column)
"""

from sklearn.preprocessing import LabelEncoder

dummy_y = ['shirt', 'short', 'shirt', 'ankel']

encoder = LabelEncoder()
encoder.fit_transform(dummy_y)

from sklearn.preprocessing import OrdinalEncoder
import pandas as pd


dummy_y =pd.DataFrame({'c1':['shirt', 'short', 'shirt', 'ankel']})

encoder = OrdinalEncoder()
encoder.fit_transform(dummy_y)

"""## Modeling"""

# https://www.tensorflow.org/api_docs/python/tf/keras/utils/set_random_seed
from tensorflow.keras.utils import set_random_seed

set_random_seed(42)

# step 1: Importing

from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.models import Sequential

#Step2: Defining
model = Sequential([Flatten(input_shape=[28, 28]),
                    Dense(100, activation='relu'), # hidden
                    Dense(50, activation='relu'), # hidden

                    Dense(10, activation='softmax')  # output
                    ])
model.summary()

model.get_weights() # random initial weights

# Step3: Compile
model.compile(loss="sparse_categorical_crossentropy", metrics=['acc'])

# Step4: Fitting (Learning)
history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, )

import pandas as pd

history_df = pd.DataFrame(history.history)
history_df

history_df[['acc', 'val_acc']].plot(xlabel='Number of Epochs')

"""### Early Stopping



"""

from tensorflow.keras.callbacks import EarlyStopping

es = EarlyStopping(
    monitor='val_acc',
    patience=5) # wait 5 epochs if the val acc didn't increase stop

history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks=[es])

"""### Class Weights

This helps with imbalanced dataset
"""

from sklearn.utils import compute_class_weight
import numpy as np
dummy_y = ['shirt', 'short', 'shirt', 'shirt']
class_weights = compute_class_weight(class_weight="balanced", classes=np.array(['short', 'shirt']), y=dummy_y)
class_weights

from sklearn.utils import compute_class_weight

class_weights = compute_class_weight(class_weight="balanced", classes=np.unique(y_train), y=y_train)
class_weights

history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks=[es],
                    class_weight= class_weights)

"""### Sample Weight"""

dummy_X = pd.DataFrame({'review':["I love", "I hate"]+['blabla']*100, 'label':['Pos', 'Neg']+['Pos']*100})
dummy_X

dummy_X['class_weight'] = 1
dummy_X['class_weight'][:2] = 100
dummy_X

history = model.fit(x_train, y_train, validation_split=0.1, epochs=100, callbacks=[es],
                    class_weight= class_weights, sample_weight=)

"""## Prediction"""

# The labels in Fashion MNIST are 0-9. We need to map them to names:
class_names = ["T-shirt/top", "Trouser", "Pullover", "Dress", "Coat",
               "Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"]

plt.figure(figsize=(10, 10))
for i in range(5):
    plt.subplot(5, 5, i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(x_test[i], cmap="binary")
    # y_train[i] is the number; class_names[y_train[i]] is the word
    plt.xlabel(class_names[y_test[i]] + ' '+str(y_test[i]))
plt.show()

#step5: Prediction
import numpy as np
y_pred = model.predict(x_test[:5], )
np.argmax(y_pred, axis=1)

model.save("emotion_model.h5")